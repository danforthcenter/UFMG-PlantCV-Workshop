{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772dfe6-61e4-47d8-9e29-688c0908f9f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 56060,
     "status": "ok",
     "timestamp": 1692851252989,
     "user": {
      "displayName": "Parag Bhatt",
      "userId": "11827230773587162498"
     },
     "user_tz": 300
    },
    "id": "WBsA8wCgMpwF",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "811100d4-b032-4ebf-9999-9b17731bdb08",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install \"altair>=5\" ipympl  plantcv\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-witness",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11215,
     "status": "ok",
     "timestamp": 1692851282320,
     "user": {
      "displayName": "Parag Bhatt",
      "userId": "11827230773587162498"
     },
     "user_tz": 300
    },
    "id": "improving-witness",
    "outputId": "9333d1a2-0fa8-4381-881d-f48b013218b9"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plantcv import plantcv as pcv\n",
    "\n",
    "# Change working directory to point to Google Drive folder where notebook is stored.\n",
    "%cd '/content/gdrive/MyDrive/Colab Notebooks/20230828-UFMG-PlantCV-Workshop/Dry-Beans-Machine-Learning-Lab'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wound",
   "metadata": {
    "id": "talented-wound"
   },
   "source": [
    "## Locate filepaths of all data saved out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-sierra",
   "metadata": {
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1692851294754,
     "user": {
      "displayName": "Parag Bhatt",
      "userId": "11827230773587162498"
     },
     "user_tz": 300
    },
    "id": "harmful-sierra"
   },
   "outputs": [],
   "source": [
    "# Get current working directory (the file path where is this notebook located?)\n",
    "path = os.getcwd()\n",
    "\n",
    "# Any file with .csv file extension will get stored into list of csv filename\n",
    "csv_filenames = glob.glob(os.path.join(path, \"*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-separate",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1692851296797,
     "user": {
      "displayName": "Parag Bhatt",
      "userId": "11827230773587162498"
     },
     "user_tz": 300
    },
    "id": "found-separate",
    "outputId": "af429cda-4aba-4b89-cafd-61dfec4009ef"
   },
   "outputs": [],
   "source": [
    "# Do you have as many data filenames as expected?\n",
    "csv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-slave",
   "metadata": {
    "id": "driving-slave"
   },
   "outputs": [],
   "source": [
    "# Define empty list for storing our various dataframes\n",
    "data_list = []\n",
    "\n",
    "# loop over the list of csv files\n",
    "for f in csv_filenames:\n",
    "\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    # Append to the list called data_list\n",
    "    data_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-illustration",
   "metadata": {
    "id": "exotic-illustration"
   },
   "outputs": [],
   "source": [
    "# Concatenate (combine) all dataframes into a single dataframe\n",
    "all_data = pd.concat(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-adapter",
   "metadata": {
    "id": "regular-adapter"
   },
   "outputs": [],
   "source": [
    "# Data wrangling steps\n",
    "# a.k.a. change the shape (structure) of the dataframe into compatible format for next steps\n",
    "\n",
    "# Filter the traits kept\n",
    "bean_features = all_data[all_data['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                                   'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                                   'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                                   'hue_circular_mean', 'hue_median'])]\n",
    "# Pivot (Transform) the dataframe from \"long\" format to \"wide\"\n",
    "bean_features_wide = pd.pivot(bean_features, index='sample', columns=\"trait\", values=\"value\")\n",
    "# Cast (change data type) to numpy array\n",
    "np_features = bean_features_wide.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-context",
   "metadata": {
    "id": "reasonable-context",
    "outputId": "405b13ce-a51a-406c-cdac-7ed598fbdeee"
   },
   "outputs": [],
   "source": [
    "# Investigate the formatted data\n",
    "bean_features_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-florida",
   "metadata": {
    "id": "appropriate-florida"
   },
   "outputs": [],
   "source": [
    "# Extract list of traits\n",
    "trait_list = bean_features_wide.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-saturn",
   "metadata": {
    "id": "alpha-saturn"
   },
   "outputs": [],
   "source": [
    "# Collect list of labels\n",
    "labels = []\n",
    "for name in trait_list:\n",
    "    bean_num = name.split(\"_\")[0]\n",
    "    labels.append(bean_num)\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-portrait",
   "metadata": {
    "id": "announced-portrait",
    "outputId": "96c2b5fa-82a2-42e6-a536-a63e38c561f9"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-generator",
   "metadata": {
    "id": "agreed-generator"
   },
   "source": [
    "Feed the trait data into the Random Forest Classifier. Giving the function data to train a model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-facing",
   "metadata": {
    "id": "popular-facing",
    "outputId": "80549cd3-052b-4252-f3b9-a5f351c0f96b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = np_features\n",
    "y_train = labels\n",
    "\n",
    "feature_names = list(bean_features_wide.columns)\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-albert",
   "metadata": {
    "id": "printable-albert"
   },
   "outputs": [],
   "source": [
    "# Extract feature importances from the model created, and standard deviations for each\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-earth",
   "metadata": {
    "id": "reflected-earth",
    "outputId": "184d953c-9f14-4f0d-aca2-db64edf23f01"
   },
   "outputs": [],
   "source": [
    "# Create a plot to display\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-exchange",
   "metadata": {
    "id": "adaptive-exchange"
   },
   "source": [
    "# STOP ðŸ›‘  HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-dominican",
   "metadata": {
    "id": "distinct-dominican"
   },
   "source": [
    "Below this point is an example of how to use a trained classifier on unlabeled data, getting collected from a bean scatter image with mixed bean types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-times",
   "metadata": {
    "id": "complicated-times"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-spank",
   "metadata": {
    "id": "stupid-spank"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-burst",
   "metadata": {
    "id": "indie-burst"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-wedding",
   "metadata": {
    "id": "neural-wedding"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outside-contamination",
   "metadata": {
    "id": "outside-contamination"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Take a bean scatter image and extract traits\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-queensland",
   "metadata": {
    "id": "mediterranean-queensland",
    "outputId": "46865081-9da7-4e53-8950-18efde0d2c25"
   },
   "outputs": [],
   "source": [
    "# Turn debugging images on\n",
    "pcv.params.debug = \"plot\"\n",
    "\n",
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in\n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "\n",
    "# Read in bean scatter image\n",
    "img, path, filename = pcv.readimage(filename=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-dream",
   "metadata": {
    "id": "olympic-dream"
   },
   "outputs": [],
   "source": [
    "# Why are they directly extracting the B*?\n",
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "\n",
    "gray = pcv.rgb2gray_lab(rgb_img=img, channel=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-editing",
   "metadata": {
    "id": "criminal-editing"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   gray_img    = grayscale image created from selected colorspace\n",
    "\n",
    "auto_mask = pcv.threshold.otsu(gray_img=gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-encyclopedia",
   "metadata": {
    "id": "asian-encyclopedia"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Set Region Of Interest\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-printer",
   "metadata": {
    "id": "little-printer"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = RGB or grayscale image for plotting\n",
    "#   x           = x coordinate of the center of ROI\n",
    "#   y           = y coordinate of the center of ROI\n",
    "#   r           = radius of the ROI to get drawn\n",
    "\n",
    "\n",
    "roi = pcv.roi.circle(img=img, x=1500, y=1700, r=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-freeze",
   "metadata": {
    "id": "mineral-freeze"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask         = Binary image\n",
    "#   roi          = Region of interest, defined in an upstream step\n",
    "#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n",
    "#                 'largest' (keep only the largest contour)\n",
    "\n",
    "filtered_mask = pcv.roi.filter(mask=auto_mask, roi=roi, roi_type=\"partial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-facility",
   "metadata": {
    "id": "pacific-facility"
   },
   "outputs": [],
   "source": [
    "pcv.params.text_size = 5\n",
    "pcv.params.text_thickness = 5\n",
    "\n",
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   num_objects = Optional parameter to limit the number of objects that will get annotated.\n",
    "\n",
    "sizes = pcv.visualize.obj_sizes(img=img, mask=filtered_mask, num_objects=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-duplicate",
   "metadata": {
    "id": "incident-duplicate"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "fill = pcv.fill(bin_img=filtered_mask, size=1000)\n",
    "#                                            ^\n",
    "#                                           |\n",
    "#                                 change this value if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-milwaukee",
   "metadata": {
    "id": "jewish-milwaukee"
   },
   "outputs": [],
   "source": [
    "# Flood fill\n",
    "\n",
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "\n",
    "clean_mask = pcv.fill_holes(bin_img=fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-exploration",
   "metadata": {
    "id": "offshore-exploration"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    mask            = mask image\n",
    "#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n",
    "#    roi_type        = (Optional) type of filtering, either partial' (for partially inside, default),\n",
    "#                       cutto' (hard cut at boundary), 'largest' (keep only the largest contour)\n",
    "\n",
    "labeled_mask, num = pcv.create_labels(mask=clean_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-bearing",
   "metadata": {
    "id": "loving-bearing"
   },
   "outputs": [],
   "source": [
    "# Extract size traits\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "shape_img = pcv.analyze.size(img=img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-leader",
   "metadata": {
    "id": "sized-leader"
   },
   "outputs": [],
   "source": [
    "# Extract color traits from each replicate\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv').\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "color_img = pcv.analyze.color(rgb_img=img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-eagle",
   "metadata": {
    "id": "ordinary-eagle"
   },
   "outputs": [],
   "source": [
    "# Save out unclassified bean trait data\n",
    "pcv.outputs.save_results(\"unclassified_bean_data.csv\", \"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-spouse",
   "metadata": {
    "id": "vertical-spouse"
   },
   "outputs": [],
   "source": [
    "# Read in CSV data and train on X traits\n",
    "f2 = \"unclassified_bean_data.csv\"\n",
    "df2 = pd.read_csv(f2)\n",
    "\n",
    "# Filter the traits kept\n",
    "bean_features2 = df2[df2['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                     'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                     'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                     'hue_circular_mean', 'hue_median'])]\n",
    "\n",
    "# Pivot the dataframe from \"long\" format to \"wide\"\n",
    "bean_features_wide2 = pd.pivot(bean_features2, index='sample', columns=\"trait\", values=\"value\")\n",
    "# Cast to numpy array\n",
    "np_features2 = bean_features_wide2.to_numpy()\n",
    "\n",
    "# Extrat list of traits\n",
    "trait_list2 = bean_features_wide2.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-poison",
   "metadata": {
    "id": "loaded-poison"
   },
   "outputs": [],
   "source": [
    "# Then predict instead of forest.fit\n",
    "X_class = np_features2\n",
    "\n",
    "classifier = forest.predict(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-vatican",
   "metadata": {
    "id": "taken-vatican"
   },
   "outputs": [],
   "source": [
    "# Investigate the predictions\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-cocktail",
   "metadata": {
    "id": "helpful-cocktail"
   },
   "outputs": [],
   "source": [
    "# Combine the predictions with PlantCV data that marks the location of each bean in the image\n",
    "classes = pd.DataFrame({\"sample\": bean_features_wide2.index.tolist(), \"class\": classifier.tolist()})\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"x\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmx\"}, inplace=True, axis=1)\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"y\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmy\"}, inplace=True, axis=1)\n",
    "\n",
    "# Label the bean class next to each bean on the image\n",
    "outimg = img.copy()\n",
    "for index, row in classes.iterrows():\n",
    "    cv2.putText(img=outimg, text=row[\"class\"], org=(int(row[\"cmx\"]), int(row[\"cmy\"])),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=pcv.params.text_size,\n",
    "                color=(255, 255, 255), thickness=pcv.params.text_thickness)\n",
    "pcv.plot_image(outimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-differential",
   "metadata": {
    "id": "personalized-differential"
   },
   "outputs": [],
   "source": [
    "# Print out a table of the probability each bean belongs to each category/class\n",
    "print(forest.classes_)\n",
    "forest.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-stuart",
   "metadata": {
    "id": "entitled-stuart"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"cells":[{"cell_type":"markdown","id":"developed-lying","metadata":{"id":"developed-lying"},"source":["<span style=\"color:maroon\">\n","\n","# Extract traits from bean images\n","    \n","## =====================================================================\n","\n","## BLANK Bean Example\n","## =====================================================================\n","\n","    \n","</span>\n"]},{"cell_type":"markdown","id":"graphic-lightweight","metadata":{"id":"graphic-lightweight"},"source":["We want to extract traits about different beans. We will measure these traits using image analysis and save data into a CSV for Machine Learning in a later activity."]},{"cell_type":"markdown","id":"brazilian-stadium","metadata":{"id":"brazilian-stadium"},"source":["<span style=\"color:purple\">\n","\n","Headers in purple will indicate a step that **might** need adjusting to parameterize the workflow to your particular image.\n","    \n","</span>\n"]},{"cell_type":"markdown","id":"prospective-figure","metadata":{"id":"prospective-figure"},"source":["## August 2023"]},{"cell_type":"code","execution_count":null,"id":"WBsA8wCgMpwF","metadata":{"id":"WBsA8wCgMpwF"},"outputs":[],"source":["%pip install \"altair>=5\" ipympl  plantcv\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# Matplotlib enables us to plot within the notebook, matplotlib is very powerful plotting library\n","%matplotlib widget\n","from google.colab import output\n","output.enable_custom_widget_manager()\n","# Imports NumPy package into notebook, essential for scientific computing\n","import numpy as np\n","# Import Altair Vegalite v5 necessary for presenting statistical graphs\n","import altair.vegalite.v5\n","# Imports PlantCV into notebook so that we can conduct plant phenotyping analyses\n","from plantcv import plantcv as pcv\n","# Imports library to handle workflow inputs compatible with parallel workflow execution.\n","from plantcv.parallel import WorkflowInputs\n","# Imports PyPlot which will provides us a MATLAB-like interface\n","from matplotlib import pyplot as plt\n","# Change working directory to point to Google Drive folder where notebook is stored.\n","%cd '/content/gdrive/MyDrive/UFMG-PlantCV-Workshop/Dry-Beans-Machine-Learning-Lab'\n","!ls"],"metadata":{"id":"z9t51Zd1RAdt"},"execution_count":null,"outputs":[],"id":"z9t51Zd1RAdt"},{"cell_type":"code","execution_count":null,"id":"strange-interference","metadata":{"id":"strange-interference","tags":[]},"outputs":[],"source":["# Print out the version of PlantCV being used by the Jupyter kernel\n","pcv.__version__\n","# Developed on the release 4.0 branch\n","# On August 28, 2023 the updated version was 4.0\n"]},{"cell_type":"markdown","id":"african-specialist","metadata":{"id":"african-specialist"},"source":["# Initialize workflow inputs & outputs"]},{"cell_type":"code","execution_count":null,"id":"accomplished-theta","metadata":{"id":"accomplished-theta","tags":[]},"outputs":[],"source":["# Set debugging parameters\n","pcv.params.debug = \"plot\"\n","pcv.params.text_size = 25\n","pcv.params.text_thickness = 25\n"]},{"cell_type":"markdown","id":"prospective-aging","metadata":{"id":"prospective-aging"},"source":["\n","What exactly is a filepath? In general, a path is a string of characters which specifies a unique location in a directory or page hierarchy. For file systems, each level in the hierarchy is a directory.\n","\n","`/home/user/python/test.py`\n","\n","In this file path, the test.py file is inside the python directory. The python directory is a subdirectory of the user directory, which is a subdirectory of the home directory. Absolute file paths specify the location of a file from the root directory in the file system structure. They are also called “full file paths” or “full paths.” In Linux, the tilde (~) is commonly used to represent a user’s home directory in a file path. Relative file paths specify the location of a file in the same folder or on the same server. In other words, a relative file path specifies a location of a file that is relative to the current directory.\n","\n","\n","(https://www.codecademy.com/resources/docs/general/file-paths)"]},{"cell_type":"markdown","id":"animated-fifteen","metadata":{"id":"animated-fifteen"},"source":["<span style=\"color:purple\">\n","\n","\n","## Read in the image\n","    \n","File extension is case sensitive.\n","    \n","Helpful notes about best practices on taking images for analysis https://danforth.workvivo.com/file/420146\n","\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"wooden-salmon","metadata":{"id":"wooden-salmon","tags":[]},"outputs":[],"source":["# Read image\n","\n","# Inputs:\n","#   filename - Image file to be read in\n","#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n","\n","bean, path1, filename1 = pcv.readimage(filename=\"\")\n","\n"]},{"cell_type":"markdown","id":"robust-photography","metadata":{"id":"robust-photography"},"source":["<span style=\"color:purple\">\n","    \n","# Rename your bean type\n","\n","### Use CamelCase and\n","## avoid spaces or underscores !!!\n","\n","</span>"]},{"cell_type":"code","execution_count":null,"id":"absent-bobby","metadata":{"id":"absent-bobby"},"outputs":[],"source":["bean_name = \"\""]},{"cell_type":"code","execution_count":null,"id":"impaired-palestine","metadata":{"id":"impaired-palestine"},"outputs":[],"source":["# Use Numpy's function \"copy\" to store your green pea image into the variable called \"img\"\n","# This will make our workflow more transferable to other images later\n","\n","img = np.copy(bean)\n"]},{"cell_type":"markdown","id":"appropriate-cross","metadata":{"id":"appropriate-cross"},"source":["## Visualize Colorspaces\n","The visualization tool converts the color image into HSV and LAB colorspaces and displays the grayscale channels in a matrix so that they can be visualized simultaneously. The idea is to select a channel that maximizes the difference between the plant and the background pixels."]},{"cell_type":"code","execution_count":null,"id":"inclusive-office","metadata":{"id":"inclusive-office"},"outputs":[],"source":["# Inputs:\n","#   rbg_img      = original image\n","#   original_img = whether to include the original RGB images in the display: True (default) or False\n","\n","all_c = pcv.visualize.colorspaces(rgb_img=,\n","                                  original_img=False\n","                                 )\n"]},{"cell_type":"markdown","id":"played-hearts","metadata":{"id":"played-hearts"},"source":["## Convert the color image to grayscale\n","Converts the input color image into the LAB colorspace and returns the B (blue-yellow) channel as a grayscale image. We have already tested ever type of bean and found that \"b\" channel did well (since we chose a blue background)."]},{"cell_type":"code","execution_count":null,"id":"official-trading","metadata":{"id":"official-trading"},"outputs":[],"source":["# Inputs:\n","#   rbg_img - original image\n","#   channel - desired colorspace ('l', 'a', or 'b')\n","\n","gray = pcv.rgb2gray_lab(rgb_img=,\n","                        channel=\"\"\n","                       )\n"]},{"cell_type":"markdown","id":"superb-cooperative","metadata":{"id":"superb-cooperative"},"source":["# Visualize the distribution of grayscale values\n","A histogram can be used to visualize the distribution of values in an image. The histogram can aid in the selection of a threshold value.\n"]},{"cell_type":"code","execution_count":null,"id":"standard-muscle","metadata":{"id":"standard-muscle"},"outputs":[],"source":["# Inputs:\n","#   img         = gray image in selected colorspace\n","#   mask        = None (default), or mask\n","#   bins        = 100 (default) or number of desired number of evenly spaced bins\n","#   lower-bound = None (default) or minimum value on x-axis\n","#   upper-bound = None (default) or maximum value on x-axis\n","#   title       = None (default) or custom plot title\n","#   hist_data   = False (default) or True (if frequency distribution data is desired)\n","\n","hist = pcv.visualize.histogram(img=,\n","                               bins=30\n","                              )\n"]},{"cell_type":"markdown","id":"infrared-paper","metadata":{"id":"infrared-paper"},"source":["## Threshold the grayscale image\n"]},{"cell_type":"code","execution_count":null,"id":"global-attack","metadata":{"id":"global-attack"},"outputs":[],"source":["# Inputs:\n","#   gray_img    = grayscale image created from selected colorspace\n","\n","auto_mask = pcv.threshold.otsu(gray_img=)"]},{"cell_type":"markdown","id":"polish-register","metadata":{"id":"polish-register"},"source":["<span style=\"color:purple\">\n","    \n","# Define Region of Interest    \n","    \n","_Highly likely that this step will need the parameters adjusted to each image_\n","\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"obvious-scheduling","metadata":{"id":"obvious-scheduling"},"outputs":[],"source":["# Inputs:\n","#   img         = RGB or grayscale image for plotting\n","#   x           = x coordinate of the center of ROI\n","#   y           = y coordinate of the center of ROI\n","#   r           = radium of the ROI to get drawn\n","\n","\n","roi = pcv.roi.circle(img=,\n","                     x=,\n","                     y=,\n","                     r=\n","                    )\n"]},{"cell_type":"code","execution_count":null,"id":"fifth-certificate","metadata":{"id":"fifth-certificate"},"outputs":[],"source":["# Inputs:\n","#   mask         = Binary image\n","#   roi          = Region of interest, defined in an upstream step\n","#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n","#                  'largest' (keep only the largest contour)\n","\n","filtered_mask = pcv.roi.filter(mask=,\n","                               roi=,\n","                               roi_type=\"\"\n","                              )\n"]},{"cell_type":"markdown","id":"amazing-architect","metadata":{"id":"amazing-architect"},"source":["## Investigate object sizes"]},{"cell_type":"code","execution_count":null,"id":"proved-corner","metadata":{"id":"proved-corner"},"outputs":[],"source":["pcv.params.text_size = 6\n","pcv.params.text_thickness = 5\n","\n","# Inputs:\n","#   img         = gray image in selected colorspace\n","#   mask        = None (default), or mask\n","#   num_objects = Optional parameter to limit the number of objects that will get annotated (default = 100).\n","\n","sizes = pcv.visualize.obj_sizes(img=,\n","                                mask=,\n","                                num_objects=\n","                               )\n"]},{"cell_type":"markdown","id":"fabulous-phrase","metadata":{"id":"fabulous-phrase"},"source":["Salt & pepper noise are small white/black pixels, respectively, in the binary mask. In this example image, the flash creates a glare that makes the centers of the beans get excluded during segmentation, but we can recover these pixels with some clean up."]},{"cell_type":"markdown","id":"choice-communications","metadata":{"id":"choice-communications"},"source":["<span style=\"color:purple\">\n","\n","\n","## Remove small background noise\n","    \n","_Thresholding mostly labeled plant pixels white but also labeled small regions of the background white. The fill function removes \"salt\" noise from the background by filtering white regions by size. The resolution of the image will factor into the average object sizes in your images so this step might require adjustment._\n","\n","</span>\n"]},{"cell_type":"code","execution_count":null,"id":"average-builder","metadata":{"id":"average-builder"},"outputs":[],"source":["# Inputs:\n","#   bin_img - binary mask image\n","#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n","\n","fill = pcv.fill(bin_img=,\n","                size= )\n","#                   /\\\n","#                   |\n","#    change this value (maybe, mostly depends on img size)\n"]},{"cell_type":"markdown","id":"quality-friend","metadata":{"id":"quality-friend"},"source":["## Flood fill \"pepper\" noise\n","\n","The `pcv.fill_holes` function does a flood fill of any missing portions that are surrounded by white pixels. This will address the glare in the center of each bean."]},{"cell_type":"code","execution_count":null,"id":"therapeutic-remark","metadata":{"id":"therapeutic-remark"},"outputs":[],"source":["# Inputs:\n","#   bin_img - binary mask image\n","\n","clean_mask = pcv.fill_holes(bin_img=\n","                           )\n"]},{"cell_type":"markdown","id":"liberal-memorabilia","metadata":{"id":"liberal-memorabilia"},"source":["## Create labeled mask\n","We want to extract traits from each bean replicate, so we need to create a mask that has unique pixel values for each identified object."]},{"cell_type":"code","execution_count":null,"id":"horizontal-camping","metadata":{"id":"horizontal-camping"},"outputs":[],"source":["# Inputs:\n","#    mask            = mask image\n","#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n","#    roi_type        = (Optional)''partial' (for partially inside, default), cutto' (hard cut at boundary),\n","#                      'largest' (keep only the largest contour)\n","\n","labeled_mask, num = pcv.create_labels(mask=\n","                                     )\n"]},{"cell_type":"markdown","id":"alive-customs","metadata":{"id":"alive-customs"},"source":["## Extract seed shape and color traits\n"]},{"cell_type":"code","execution_count":null,"id":"formal-summit","metadata":{"id":"formal-summit"},"outputs":[],"source":["# Extract size traits\n","\n","# Inputs:\n","        #   img          = RGB image for debugging\n","        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n","        #   n_labels     = Total number expected individual objects (default = 1).\n","        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n","\n","shape_img = pcv.analyze.size(img=,\n","                             labeled_mask=,\n","                             n_labels=,\n","                             label=str(bean_name) + \"_\")\n"]},{"cell_type":"code","execution_count":null,"id":"divine-january","metadata":{"id":"divine-january"},"outputs":[],"source":["pcv.params.debug = \"plot\"\n","\n","df, start, space = pcv.transform.find_color_card(rgb_img=,\n","                                                 label=str(bean_name) + \"_\")\n","\n","cc_mask = pcv.transform.create_color_card_mask(rgb_img=,\n","                                               radius=10,\n","                                               start_coord=,\n","                                               spacing=space,\n","                                               ncols=4, nrows=6)\n","#                                                  / \\      / \\\n","#                                                   |        |\n","#                Might need to be swapped depending on color card orientation\n"]},{"cell_type":"markdown","id":"characteristic-press","metadata":{"id":"characteristic-press"},"source":["# Back to data extraction! Color data next"]},{"cell_type":"code","execution_count":null,"id":"romance-firmware","metadata":{"id":"romance-firmware"},"outputs":[],"source":["# Extract color traits from each replicate\n","\n","# Inputs:\n","        #   img          = RGB image for debugging\n","        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n","        #   n_labels     = Total number expected individual objects (default = 1).\n","        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv')\n","        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n","\n","pcv.params.debug = \"plot\"\n","\n","color_img = pcv.analyze.color(rgb_img=,\n","                              labeled_mask=,\n","                              n_labels=,\n","                              colorspaces=\"hsv\",\n","                              label=str(bean_name) + \"_\")\n"]},{"cell_type":"code","execution_count":null,"id":"capital-creek","metadata":{"id":"capital-creek"},"outputs":[],"source":["# Look at what has been stored into the Outputs class as observations from our workflow\n","# Pretty unreadable due to the heirarchical format, but we just extracted TONS of raw phenotype data\n","\n","pcv.outputs.observations"]},{"cell_type":"markdown","id":"scenic-error","metadata":{"id":"scenic-error"},"source":["# How large is the first bean?"]},{"cell_type":"code","execution_count":null,"id":"british-secretary","metadata":{"id":"british-secretary"},"outputs":[],"source":["# Index the dictionary of traits to look at the area for one replicate\n","\n","indexing_name = str(bean_name) + \"_1\"\n","pcv.outputs.observations[indexing_name]['area']['value']\n"]},{"cell_type":"markdown","id":"vertical-syndicate","metadata":{"id":"vertical-syndicate"},"source":["## Save results\n","\n","During analysis, measurements are stored in the background in the outputs recorder.\n","\n","This example includes image analysis for 'area', 'convex_hull_area', 'solidity', 'perimeter', 'width', 'height', 'longest_path', 'center_of_mass, 'convex_hull_vertices', 'object_in_frame', 'ellipse_center', 'ellipse_major_axis', 'ellipse_minor_axis', 'ellipse_angle', 'ellipse_eccentricity' using `pcv.analyze.size` and color analysis using `pcv.analyze.color`.\n","\n","Here, results are saved to a CSV file. Filename will update with bean name set at top of this workflow."]},{"cell_type":"code","execution_count":null,"id":"specific-height","metadata":{"id":"specific-height"},"outputs":[],"source":["csv_filename = str(bean_name) + \"_csv.csv\"\n","pcv.outputs.save_results(csv_filename, \"csv\")\n"]},{"cell_type":"markdown","id":"gorgeous-viking","metadata":{"id":"gorgeous-viking"},"source":["Now we can go look for the CSV file that we just saved out."]},{"cell_type":"markdown","id":"numerical-aurora","metadata":{"id":"numerical-aurora"},"source":["<span style=\"color:maroon\">\n","\n","# Duplicate this workflow\n","\n","_Click the (File) tab in the top left corner. (Make a copy ... ) And rename the new jupyter notebook with your next bean type._\n","    \n","</span>"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}